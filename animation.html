<!--
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
* Modified by Chad McKell
-->

<!DOCTYPE html>
<html>
<head>
  
   <!-- Basic Page Needs -->
  <meta charset="utf-8">
  <title>Animation</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS -->
  <link rel="stylesheet" href="css/custom.css">
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" type="image/png" href="images/fairy2.jpg">
  
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
  </script>
  

  <style>
    a {
      text-decoration: none;
      color: rgb(61, 68, 200); 
    } 
    </style>

</head>
<body>


  <header class="header">
    <a href="index" class="logo">CHAD MCKELL</a>
    <input class="menu-btn" type="checkbox" id="menu-btn" />
    <label class="menu-icon" for="menu-btn"><span class="navicon"></span></label>
    <ul class="menu">
      <li><a href="research">Research</a></li>
      <li><a href="publications">Publications</a></li>
      <li><a href="portfolio">Portfolio</a></li>
      <li><a href="teaching">Teaching</a></li>
      <li><a href="about">About</a></li>
    </ul>
  </header>
  
    
  <!-- <header>
    <div class="nav">
        
    <a id="menu-icon"></a>
        
      <ul>
          <li><a href="index">Home</a></li>
          <li><a href="research">Research</a></li>
          <li><a href="publications">Publications</a></li>
          <li><a href="teaching">Teaching</a></li>
          <li><a href="about">About</a></li>
      </ul>
      
    </div>
  </header> -->

  <div class="banner">
	  <img style="width:100%;" id="image" src="images/desert_cover.jpg">
  </div>

  <div class="section">
    <div class="container">
     
     
 
    <br>
    <h3><b>Sound Synthesis for Computer Animation</b></h3>

      <h5><b>Musical Instrument Synthesis</b></h5>
      <p> 
        <div style="LINE-HEIGHT:18px; text-align:left"><font color="grey">Strings, membranes, and plates are the basic building 
        blocks of musical instruments. Using modal synthesis and finite-difference time-domain (FDTD) methods, I simulated sounds  
        corresponding to each of these musical instrument objects. In the case of plates, I modeled different materials and 
        excitation mechanisms. Audio samples of each musical instrument object are provided below. I'm currently in the process of 
        synchronizing the sounds with computer animations. As preparation, I have graphically rendered musical instruments to use 
        in these animations (see violin below).
      </font></div>
      <!-- Rigid bodies&mdash;such as strings, membranes, and plates&mdash;are the basic building blocks of common acoustic systems 
        in computer animation, including musical instruments 

        Various physical modeling schemes exist for simulating these objects, including modal 
        synthesis and finite-difference time-domain (FDTD) methods. I simulated several categories of object vibrations by solving for 
        the displacement of a point located on the object over time using one of these methods.
      
      -->
      <br>
      <table>
        <tr>
          <td>String</td>
          <td>
            <audio controls>
              <source src="audio/string_fdtd.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>Membrane</td>
          <td>
            <audio controls>
              <source src="audio/membrane.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
          <tr>
            <td>Plate</td>
            <td>
              <audio controls>
                <source src="audio/plate_metal.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
      </table>
      <img src="images/violin_render.png" style="width:100%">
      </p>

      <hr>



      <h5><b>Speech Synthesis</b></h5>
      <p> 
        <div style="LINE-HEIGHT:18px; text-align:left"><font color="grey">Wolfgang von Kempelen created the first known speech synthesizer in 1791. The device used a variety of parts to 
          imitate human speech&mdash;a bellows for the lungs, a reed for the vocal folds, tubes for the various vocal-tract geometries, 
          and so on. By reproducing the subtleties of linguistic sounds from observations of the acoustic and physiological 
          mechanisms of speech, Kempelen set the stage for more advanced speech synthesis techniques that would emerge 
          centuries later.
          
          <br> <br>

          Physical modeling speech synthesis is a computational approach to artificial voice production that generates 
          acoustic sounds by numerically solving a mathematical model of speech. As part of my special project 
          <a href="/pdf/speech_2017.pdf" target="_blank"><b>dissertation</b></a> in Acoustics and Music Technology at the University of Edinburgh, 
          I developed physical modeling simulations of vocal-tract sound propagation by solving Webster's equation with
          finite-difference time-domain (FDTD) methods. For another course project, I also created a unit selection speech 
          synthesizer, which concatenates individual diphones of speech. Code from my 
          <a href="https://github.com/chadmckell/FDTDSpeech" target="_blank"><b>FDTD</b></a> and <a href="https://github.com/chadmckell/UnitSpeech" target="_blank"><b>unit selection</b></a>
          speech synthesizers is available on my GitHub page. To demonstrate my simulations, I used the English phrase <i>I owe you a yo-yo</i>.
          I chose this phrase because it contains only vowels and diphthongs. Other speech sounds, like consonants
          and glottal fry, were left for future research. 
          <br><br>
          Similar to musical instrument synthesis discussed above, I plan to synchronize speech sounds with facial animations. I have built 
          simple character rigs (like the rig of a dragon shown below) to use in this research.
        </font></div>
          <br>
          <table>
            <tr>
              <td>FDTD Speech</td>
              <td>
                <audio controls>
                  <source src="audio/speech_fdtd_quiet.wav" type="audio/wav">
                </audio>
              </td>
            </tr>
            <tr>
              <td>Unit Selection</td>
              <td>
                <audio controls>
                  <source src="audio/speech_unit.wav" type="audio/wav">
                </audio>
              </td>
            </tr>
  
          </table>
  

          <img src="images/dragon_render.png" style="width:100%">

          <br><br>
          <font color="grey">
          <h6><b>References</b></h6>
          <div style="LINE-HEIGHT:18px; text-align:left">
                 <ol>
                  <li><b>C. McKell</b>. <i>Finite-Difference Simulations of Speech with Wall Vibration Losses </i>, Special Project Master's Dissertation, University of Edinburgh, Acoustics and Audio Group, April 2017. [<a href="/pdf/speech_2017.pdf"  target="_blank"><b>paper</b></a>]</li> 
                </ol>
                </font></div>
      </p>

      <hr>

      <h5><b>Room Acoustics</b></h5>
          <p> 
            <div style="LINE-HEIGHT:18px; text-align:left"><font color="grey">I modeled room reverberation using the image-source method. The model simulates the impulse response of a
            room and then convolves the impulse response with the original input audio in the time domain. For simplicity,
            I assumed that the walls of the room were flat and positioned perpendicular to each other.
            
            <br> <br>
            
            The equation that defines the magnitude \(g\) of each impulse in the simulated impulse response takes the form
            
            $$g = {(\sqrt{1-\alpha})^w \over l}$$
            
            where \(\alpha\) is the absorption coefficient of the walls, \(w\) is the total number of collisions between the 
            sound wave and the walls for each image source, and \(l\) is the total distance between the receiver and each 
            image source. (Note that high absorption values correspond to low reverberant rooms). The MATLAB 
            <a href="https://github.com/chadmckell/ImageSourceBasic" target="_blank"><b>code</b></a> for my reverb model is available on my GitHub
            page.
          </font></div>
          </p>

        <table>
          <tr>
            <td>Dry</td>
            <td>
              <audio controls>
                <source src="audio/guitar_dry.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
          <tr>
            <td>High Absorption</td> 
            <td>
              <audio controls>
                <source src="audio/reverb_high.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
          <tr>
            <td>Low Absorption</td>
            <td>
              <audio controls>
                <source src="audio/reverb_low.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
        </table>
  

    </div>
  </div>




<!--
<div class="section">
    <div class="container">
      <div class="one-half column">
        <br>
        <h4><b>Sound Synthesis for Animation</b></h4>
        <h5><b>String Synthesis</b></h5>
          <p> 
            <div style="LINE-HEIGHT:16px; text-align:left"><font color="grey">Strings are the basic building blocks of many musical instruments, including guitars, violins, and dulcimers.
            Various physical modeling schemes exist for modeling strings, such as the Karplus-Strong technique,
            modal synthesis, and finite-difference time-domain (FDTD) methods. The displacement \(u = u(x, t)\) of a lossy 
            forced string of finite length \(L\) and fixed boundary conditions is described by the 1D wave equation
            with loss and forcing 
            
            $$u_{tt} = c^2 u_{xx} - 2\sigma_0 u_t + \delta F$$

            where \(c\) is the speed of sound in the string, \(\sigma_0\) is a non-negative damping constant, 
            \(\delta = \delta(x-x_i)\) is the 1D delta function centered at the excitation location \(x_i\), and \(F\) is the 
            time-dependent forcing signal.
            
            <br> <br>
            
            I modeled string vibrations by solving for the displacement \(u\) using FDTD and modal synthesis. For 
            comparison, I also simulated string vibrations using the Karplus-Strong (KS) approach, which 
            implements delays to approximate the vibrations.
          </font></div>
          </p>
      </div>
      <div class="one-half column">
        <br> <br> <br><br>
        <img src="images/string.png" style="width:85%">
        <video width="500" height="300" loop autoplay>
        <source src="video/string.mp4" type="video/mp4">
        </video>
        <table>
          <tr>
            <td>FDTD</td>
            <td>
              <audio controls>
                <source src="audio/string_fdtd.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
          <tr>
            <td>Modal</td>
            <td>
              <audio controls>
                <source src="audio/string_modal.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
          <tr>
            <td>KS</td>
            <td>
              <audio controls>
                <source src="audio/string_ks.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
        </table>
      </div>

    </div>
  </div>
  
  
    <div class="section">
    <div class="container">
      <div class="one-half column">
        <h5><b>Membrane Synthesis</b></h5>
          <p> 
            <div style="LINE-HEIGHT:16px; text-align:left"><font color="grey">Percussion instruments like kick drums and toms are made of membranes. The displacement \(u = u(x,y,t)\) of a lossy 
            forced rectangular membrane of finite dimensions \(L_x \times L_y\) and fixed boundary conditions is described by
            the 2D wave equation with loss and forcing
            
            $$u_{tt} = c^2 \Delta u - 2\sigma_0 u_t + \delta F$$
            
            where \(c\) is the speed of sound in the membrane, \(\sigma_0\) is a non-negative damping constant, 
            \(\delta = \delta(x-x_i, y-y_i)\) is the 2D delta function centered at the excitation location \((x_i, y_i)\), 
            and \(F\) is the time-dependent forcing signal. I used modal synthesis to simulate vibrations from a membrane.</font></div>
          </p>
      </div>
      <div class="one-half column">
        <br> <br> 
        <img src="images/membrane.jpg" style="width:85%">
        <video width="500" height="300" loop autoplay>
        <source src="video/membrane.mp4" type="video/mp4">
        </video>
        <table>
          <tr>
            <td>Membrane</td>
            <td>
              <audio controls>
                <source src="audio/membrane.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
        </table>
      </div>
    </div>
  </div>
  
  
  
  <div class="section">
    <div class="container">
      <div class="one-half column">
        <h5><b>Plate Synthesis</b></h5>
          <p> 
            <div style="LINE-HEIGHT:16px; text-align:left"><font color="grey">Many musical instruments are made of plates. For example, the soundboard of a piano and the fretboard of a guitar
            can both be modeled as rectangular plates. The displacement \(u = u(x,y,t)\) of a lossy forced rectangular plate 
            of finite dimensions \(L_x \times L_y\) and fixed boundary conditions is described by the Kirchhoff thin plate 
            equation with loss and forcing
            
            $$u_{tt} = -\kappa^2 \Delta \Delta u - 2\sigma_0 u_t + \delta F$$
            
            where \(\kappa\) is the stiffness parameter, \(\sigma_0\) is a non-negative damping constant, 
            \(\delta = \delta(x-x_i, y-y_i)\) is the 2D delta function centered at the excitation location \((x_i, y_i)\), 
            and \(F\) is the time-dependent forcing signal.
            
            I used modal synthesis to simulate vibrations from plates made of different materials, such as metal and wood. 
            I also modeled different excitations, including impulses and scratches.</font></div>
          </p>
      </div>
      <div class="one-half column">
        <br> <br>
        <img src="images/plate.png" style="width:85%">
        <video width="500" height="300" loop autoplay>
        <source src="video/plate.mp4" type="video/mp4">
        </video>
        <table>
          <tr>
            <td>Metal</td>
            <td>
              <audio controls>
                <source src="audio/plate_metal.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
          <tr>
            <td>Wood</td> 
            <td>
              <audio controls>
                <source src="audio/plate_wood.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
        </table>
      </div>
    </div>
  </div>






  <div class="section">
    <div class="container">
      <div class="one-half column">
        <h5><b>Speech Synthesis</b></h5>
          <p> 
            <div style="LINE-HEIGHT:16px; text-align:left"><font color="grey">Wolfgang von Kempelen created the first known speech synthesizer in 1791. The device used a variety of parts to 
              imitate human speech&mdash;a bellows for the lungs, a reed for the vocal folds, tubes for the various vocal-tract geometries, 
              and so on. By reproducing the subtleties of linguistic sounds from observations of the acoustic and physiological 
              mechanisms of speech, Kempelen set the stage for more advanced speech synthesis techniques that would emerge 
              centuries later.
              
              <br> <br>
  
              Physical modeling speech synthesis is a computational approach to artificial voice production that generates 
              acoustic sounds by numerically solving a mathematical model of speech. As part of my special project 
              <a href="/pdf/speech_2017.pdf">dissertation</a> in Acoustics and Music Technology at the University of Edinburgh, 
              I developed physical modeling simulations of vocal-tract sound propagation by solving Webster's equation with
              finite-difference time-domain (FDTD) methods. For another course project, I also created a unit selection (US) speech 
              synthesizer, which concatenates individual diphones of speech. Code from my 
              <a href="https://github.com/chadmckell/FDTDSpeech">FDTD</a> and <a href="https://github.com/chadmckell/UnitSpeech">unit selection</a>
              speech synthesizers is available on my GitHub page.
              
              <br> <br>
              
              To demonstrate my simulations, I used the English phrase 
              
              <br><br>
             
              <center><i>I owe you a yo-yo.</i></center> 
              
              <br>
              
              I chose this phrase because it contains only vowels and diphthongs. Other speech sounds, like consonants
              and glottal fry, were reserved for future research.</font></div>
          </p>
      </div>

      <div class="one-half column">
        <br> <br> 
        <img src="images/speech.jpg" style="width:85%">
        <table>
          <tr>
            <td>FDTD</td>
            <td>
              <audio controls>
                <source src="audio/speech_fdtd_quiet.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
          <tr>
            <td>US</td>
            <td>
              <audio controls>
                <source src="audio/speech_unit.wav" type="audio/wav">
              </audio>
            </td>
          </tr>
        </table>
      </div>
    </div>
  </div>
-->




<br>

<div class="footer"> 
  <a href="https://vimeo.com/mckell" target="_blank"><i class="fa fa-vimeo-square" style="font-size:36px"></i></a>
  <a href="https://github.com/chadmckell" target="_blank"><i class="fa fa-github" style="font-size:36px"></i> </a>
  <a href="https://www.linkedin.com/in/chadmckell/" target="_blank"><i class="fa fa-linkedin-square" style="font-size:36px"></i></a>
  <!-- <a href="https://brownian.bandcamp.com/releases" target="_blank"><i class="fa fa-bandcamp" style="font-size:36px"></i></a> -->
  <br> <br>
  <font color="white">Copyright &copy 2009&ndash;2020. Chad McKell. All Rights Reserved.</font>
</div>

</body>
</html>
